# -*- coding: utf-8 -*-
"""Speed+detection_till_now final08/10/25.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18VzB4UlolwcVmkuE9ZEKtjNdICaH-p5_
"""

!pip install ultralytics supervision opencv-python numpy
!pip install deep_sort_realtime

# Forklift Speed Detection and Tracking
# This script uses YOLO for object detection and a custom tracker with a Kalman filter
# to monitor forklifts in a video feed and estimate their speed.

import cv2
from ultralytics import YOLO
import numpy as np
from collections import defaultdict, deque
import csv
from datetime import datetime
import math

# Optional: use scipy for optimal assignment if available
try:
    from scipy.optimize import linear_sum_assignment
    HAS_SCIPY = True
except ImportError:
    HAS_SCIPY = False

# ---------------- CONFIG ----------------
# --- File Paths (Update these for your system)
VIDEO_PATH = '/content/drive/MyDrive/trimmed_video/trimmed_video10.mp4'
MODEL_PATH = '/content/drive/MyDrive/Models/Forklift_300.pt' # Using a default model, replace with your 'Forklift_300.pt'
OUTPUT_PATH = 'output_video_cleaned.mp4'
CSV_OUTPUT_PATH = 'tracking_details_cleaned.csv'

# --- Calibration
# Set the ratio of pixels to meters. Measure a known distance in the video frame.
# For example, if a 1-meter object is 100 pixels long in the video:
REFERENCE_ENABLED = True
REFERENCE_PIXELS = 100.0  # The length in pixels of your reference object
REFERENCE_METERS = 1.0    # The real-world length in meters of the reference object

if REFERENCE_ENABLED and REFERENCE_PIXELS > 1:
    PIXELS_TO_METERS = REFERENCE_METERS / REFERENCE_PIXELS
else:
    # Fallback default value if calibration is disabled
    PIXELS_TO_METERS = 0.032

# --- Detection and Tracker Parameters
CONFIDENCE_THRESHOLD = 0.3
IOU_THRESHOLD = 0.45
MISS_TOLERANCE_FRAMES = 40      # Max frames to keep a lost track before deleting
NEW_TRACK_MIN_CONF = 0.25       # Min confidence to start a new track
# Weights for matching a track to a detection
APPEARANCE_WEIGHT = 0.35
IOU_WEIGHT = 0.55
MOTION_WEIGHT = 0.10
HIST_BINS = [16, 16, 8]         # HSV histogram bins for appearance feature

# --- Visuals
SHOW_TRAJECTORIES = True
BBOX_THICKNESS = 4
FONT_SCALE = 0.8
TEXT_THICKNESS = 2
BBOX_COLOR_DEFAULT = (0, 255, 255)   # BGR (Yellow)
TEXT_COLOR = (255, 255, 255)         # White
TEXT_BG_COLOR = (30, 30, 30)           # Dark Gray

# --- System
DEVICE = 'cpu'
# ----------------------------------------


class KalmanFilter2D:
    """A simple 2D Kalman Filter for object tracking."""
    def __init__(self, x, y, dt=1.0):
        # State: [x, y, vx, vy]
        self.dt = dt
        self.x = np.array([x, y, 0., 0.], dtype=float)
        self.P = np.eye(4) * 50.
        self.F = np.array([[1,0,self.dt,0],[0,1,0,self.dt],[0,0,1,0],[0,0,0,1.]], dtype=float)
        self.Q = np.eye(4) * 0.01
        self.H = np.array([[1,0,0,0],[0,1,0,0]], dtype=float)
        self.R = np.eye(2) * 25.

    def predict(self, dt=None):
        if dt is not None and dt != self.dt:
            self.dt = dt
            self.F = np.array([[1,0,self.dt,0],[0,1,0,self.dt],[0,0,1,0],[0,0,0,1.]], dtype=float)
        self.x = self.F @ self.x
        self.P = self.F @ self.P @ self.F.T + self.Q
        return float(self.x[0]), float(self.x[1])

    def update(self, mx, my):
        z = np.array([mx, my])
        y = z - (self.H @ self.x)
        S = self.H @ self.P @ self.H.T + self.R
        K = self.P @ self.H.T @ np.linalg.inv(S)
        self.x = self.x + K @ y
        self.P = (np.eye(4) - K @ self.H) @ self.P
        return float(self.x[0]), float(self.x[1])


def hsv_histogram(image, bbox):
    """Calculates a normalized HSV histogram for a bounding box region."""
    x1, y1, x2, y2 = map(int, bbox)
    roi = image[y1:y2, x1:x2]
    if roi.size == 0:
        return np.zeros(sum(HIST_BINS), dtype=np.float32)
    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
    hist = cv2.calcHist([hsv], [0, 1, 2], None, HIST_BINS, [0, 180, 0, 256, 0, 256])
    return cv2.normalize(hist, hist).flatten()


def appearance_sim(hist1, hist2):
    """Calculates appearance similarity based on histogram comparison."""
    if hist1 is None or hist2 is None:
        return 0.0
    # Bhattacharyya distance converted to similarity score [0, 1]
    d = cv2.compareHist(hist1.astype('float32'), hist2.astype('float32'), cv2.HISTCMP_BHATTACHARYYA)
    return float(max(0.0, 1.0 - d))


def iou(boxA, boxB):
    """Calculates Intersection over Union for two bounding boxes."""
    xA = max(boxA[0], boxB[0])
    yA = max(boxA[1], boxB[1])
    xB = min(boxA[2], boxB[2])
    yB = min(boxA[3], boxB[3])
    inter_area = max(0, xB - xA) * max(0, yB - yA)
    boxA_area = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])
    boxB_area = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])
    denominator = float(boxA_area + boxB_area - inter_area)
    return inter_area / denominator if denominator > 0 else 0.0


class Track:
    """Represents a single tracked object."""
    _next_id = 1
    def __init__(self, bbox, conf, frame_idx, feature, dt=1.0):
        self.id = Track._next_id
        Track._next_id += 1
        cx, cy = (bbox[0] + bbox[2]) / 2.0, (bbox[1] + bbox[3]) / 2.0
        self.bbox = bbox
        self.conf = conf
        self.kf = KalmanFilter2D(cx, cy, dt=dt)
        self.feature = feature
        self.last_seen = frame_idx
        self.misses = 0
        self.history = deque(maxlen=50)
        self.history.append((cx, cy))
        self.active = True
        self.prev_bbox = bbox # For temporal smoothing

    def predict(self, dt=1.0):
        return self.kf.predict(dt)

    def update(self, bbox, conf, frame_idx, feature, frame_dt=1.0):
        cx, cy = (bbox[0] + bbox[2]) / 2.0, (bbox[1] + bbox[3]) / 2.0
        self.kf.update(cx, cy)
        self.bbox = bbox
        self.conf = conf
        self.feature = feature
        self.last_seen = frame_idx
        self.misses = 0
        self.history.append((cx, cy))

    def mark_missed(self):
        self.misses += 1
        if self.misses > MISS_TOLERANCE_FRAMES:
            self.active = False

    def get_center(self):
        return (self.bbox[0] + self.bbox[2]) / 2.0, (self.bbox[1] + self.bbox[3]) / 2.0


def match_tracks_detections(tracks, detections, frame_dt):
    """Matches active tracks to new detections using a combination of IoU, appearance, and motion."""
    n, m = len(tracks), len(detections)
    if n == 0 or m == 0:
        return [], list(range(m)), list(range(n))

    cost_matrix = np.ones((n, m), dtype=np.float32)
    for i, t in enumerate(tracks):
        px, py = t.predict(dt=frame_dt)
        for j, d in enumerate(detections):
            dbox = d['bbox']
            iou_score = iou(t.bbox, dbox)
            app_score = appearance_sim(t.feature, d['feature'])

            # Motion similarity based on distance from predicted position
            dx, dy = px - (dbox[0] + dbox[2]) / 2.0, py - (dbox[1] + dbox[3]) / 2.0
            dist = np.sqrt(dx*dx + dy*dy)
            motion_score = np.exp(-dist / max(1.0, (np.mean([dbox[2]-dbox[0], dbox[3]-dbox[1]]) / 2.0)))

            similarity = IOU_WEIGHT * iou_score + APPEARANCE_WEIGHT * app_score + MOTION_WEIGHT * motion_score
            cost_matrix[i, j] = 1.0 - similarity

    if HAS_SCIPY:
        row_ind, col_ind = linear_sum_assignment(cost_matrix)
        matched_indices = [(r, c) for r, c in zip(row_ind, col_ind) if cost_matrix[r, c] < 0.85]
    else: # Fallback to greedy matching if scipy is not installed
        matched_indices = []
        cost_copy = cost_matrix.copy()
        while np.min(cost_copy) < 0.85:
            r, c = np.unravel_index(np.argmin(cost_copy), cost_copy.shape)
            matched_indices.append((r, c))
            cost_copy[r, :] = 1.0
            cost_copy[:, c] = 1.0

    unmatched_trks = set(range(n))
    unmatched_dets = set(range(m))
    for r, c in matched_indices:
        unmatched_trks.discard(r)
        unmatched_dets.discard(c)

    return matched_indices, list(unmatched_dets), list(unmatched_trks)

# ---------------- DATASHEET & PHYSICS (Replace with your forklift's data) ----------------
# This data is used to set realistic speed and acceleration limits.
DATASHEET_ENTRIES = [
    # {Load_kg, Max_Speed_Loaded_km_h, Max_Speed_Unloaded_km_h, Accel_Loaded_s, Accel_Unloaded_s}
    { 'Load_kg': 0,    'Max_Speed_Loaded_km_h': 18.0, 'Max_Speed_Unloaded_km_h': 22.0, 'Accel_Loaded_s': 6.0, 'Accel_Unloaded_s': 5.0 },
    { 'Load_kg': 1000, 'Max_Speed_Loaded_km_h': 16.0, 'Max_Speed_Unloaded_km_h': 20.0, 'Accel_Loaded_s': 7.0, 'Accel_Unloaded_s': 5.5 },
    { 'Load_kg': 2000, 'Max_Speed_Loaded_km_h': 14.0, 'Max_Speed_Unloaded_km_h': 18.0, 'Accel_Loaded_s': 8.0, 'Accel_Unloaded_s': 6.0 },
]

_loads = np.array([r['Load_kg'] for r in DATASHEET_ENTRIES], dtype=float)
_loaded_speeds = np.array([r['Max_Speed_Loaded_km_h'] for r in DATASHEET_ENTRIES], dtype=float)
_unloaded_speeds = np.array([r['Max_Speed_Unloaded_km_h'] for r in DATASHEET_ENTRIES], dtype=float)

def interp_loaded_max_kmh(est_load_kg):
    return float(np.interp(est_load_kg, _loads, _loaded_speeds)) if len(_loads) > 0 else 16.0

def interp_unloaded_max_kmh(est_load_kg):
    return float(np.interp(est_load_kg, _loads, _unloaded_speeds)) if len(_loads) > 0 else 20.0

ABSOLUTE_MAX_KMH = max(float(_unloaded_speeds.max()) if len(_unloaded_speeds)>0 else 0, float(_loaded_speeds.max()) if len(_loaded_speeds)>0 else 0, 60.0)
# ----------------- DRAWING HELPERS -----------------

def export_tracking_data_to_csv(object_stats, csv_path, video_info):
    """Exports aggregated tracking statistics to a CSV file."""
    try:
        with open(csv_path, 'w', newline='') as f:
            f.write(f"# Forklift Tracking Analysis Report\n")
            f.write(f"# Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"# Video: {video_info['path']}\n")
            fieldnames = ['Track_ID', 'Frames', 'Max_Speed_kmh', 'Avg_Speed_kmh', 'Total_Distance_m']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            for track_id, stats in object_stats.items():
                speeds = stats.get('speeds', [])
                writer.writerow({
                    'Track_ID': track_id,
                    'Frames': stats.get('frames', 0),
                    'Max_Speed_kmh': round(max(speeds) if speeds else 0, 2),
                    'Avg_Speed_kmh': round(float(np.mean(speeds)) if speeds else 0, 2),
                    'Total_Distance_m': round(stats.get('distance', 0), 2)
                })
        print(f"ðŸ“Š Tracking data exported to: '{csv_path}'")
    except Exception as e:
        print(f"âŒ Failed to export CSV: {e}")


def draw_text_with_background(img, text, pos, scale=FONT_SCALE, thick=TEXT_THICKNESS,
                              t_color=TEXT_COLOR, bg_color=TEXT_BG_COLOR, pad=6):
    """Draws text with a dark, semi-transparent background for better visibility."""
    font = cv2.FONT_HERSHEY_DUPLEX
    (tw, th), baseline = cv2.getTextSize(text, font, scale, thick)
    x, y = pos
    bg_tl = (x - pad, y - th - pad)
    bg_br = (x + tw + pad, y + baseline + pad)
    overlay = img.copy()
    cv2.rectangle(overlay, bg_tl, bg_br, bg_color, -1)
    cv2.addWeighted(overlay, 0.7, img, 0.3, 0, img) # Blend for transparency
    cv2.putText(img, text, (x, y), font, scale, t_color, thick, cv2.LINE_AA)
    return th + pad * 2 + 2


def draw_box_with_label(img, bbox, label_lines, color=BBOX_COLOR_DEFAULT, thickness=BBOX_THICKNESS):
    """Draws a bounding box and a stacked label above it."""
    x1, y1, x2, y2 = map(int, bbox)
    cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)
    y_pos = y1 - 8
    for line in reversed(label_lines):
        y_pos -= draw_text_with_background(img, line, (x1 + 4, y_pos))


# ----------------- BBOX REFINEMENT -----------------

def clamp_bbox(bbox, w, h):
    x1, y1, x2, y2 = bbox
    return (max(0, int(x1)), max(0, int(y1)), min(w, int(x2)), min(h, int(y2)))


def blend_bbox(prev_bbox, new_bbox, alpha=0.6):
    """Temporally smooths a bounding box by blending with the previous one."""
    x1 = int(alpha * new_bbox[0] + (1 - alpha) * prev_bbox[0])
    y1 = int(alpha * new_bbox[1] + (1 - alpha) * prev_bbox[1])
    x2 = int(alpha * new_bbox[2] + (1 - alpha) * prev_bbox[2])
    y2 = int(alpha * new_bbox[3] + (1 - alpha) * prev_bbox[3])
    return (x1, y1, x2, y2)

# ----------------- MAIN PROCESSING LOOP -----------------

def main():
    try:
        model = YOLO(MODEL_PATH)
        print(f"âœ… Loaded model. Classes: {model.names}")
    except Exception as e:
        print(f"âŒ Failed to load model '{MODEL_PATH}': {e}")
        return

    cap = cv2.VideoCapture(VIDEO_PATH)
    if not cap.isOpened():
        print(f"âŒ Cannot open video: {VIDEO_PATH}")
        return

    fps = cap.get(cv2.CAP_PROP_FPS) or 25.0
    frame_dt = 1.0 / fps
    frame_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)

    out = cv2.VideoWriter(OUTPUT_PATH, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_w, frame_h))

    # --- Tracking State ---
    tracks = []
    lost_tracks = {}
    objects_stats = defaultdict(lambda: {'speeds': [], 'frames': 0, 'distance': 0.0})
    bbox_size_history = defaultdict(lambda: deque(maxlen=30))

    # Per-track state for smoothing and visualization
    track_speed_history = defaultdict(lambda: deque(maxlen=8))
    track_prev_valid_speed = {}
    track_smoothed = {}
    track_load_fraction = {}

    frame_idx = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        frame_idx += 1

        # --- Detection ---
        results = model(frame, conf=CONFIDENCE_THRESHOLD, iou=IOU_THRESHOLD, device=DEVICE, verbose=False)
        detections = []
        if results[0].boxes is not None:
            for conf, cls, xyxy in zip(results[0].boxes.conf, results[0].boxes.cls, results[0].boxes.xyxy):
                if 'forklift' in model.names[int(cls)].lower():
                    bbox = clamp_bbox(xyxy.cpu().numpy(), frame_w, frame_h)
                    detections.append({
                        'bbox': bbox,
                        'conf': float(conf),
                        'feature': hsv_histogram(frame, bbox)
                    })

        # --- Prediction and Matching ---
        for t in tracks:
            t.predict(frame_dt)
        matched, unmatched_dets, unmatched_trks = match_tracks_detections(tracks, detections, frame_dt)

        # --- Update Matched Tracks ---
        for trk_idx, det_idx in matched:
            trk, det = tracks[trk_idx], detections[det_idx]
            trk.update(det['bbox'], det['conf'], frame_idx, det['feature'], frame_dt)

            # Temporal smoothing of bbox
            sm_bbox = blend_bbox(trk.prev_bbox, det['bbox'], alpha=0.65)
            trk.bbox = sm_bbox
            trk.prev_bbox = sm_bbox
            bbox_size_history[trk.id].append((sm_bbox[2]-sm_bbox[0]) * (sm_bbox[3]-sm_bbox[1]))

            # --- Speed Calculation ---
            # 1. Kalman filter velocity
            vx, vy = float(trk.kf.x[2]), float(trk.kf.x[3])
            kf_speed_kmh = math.hypot(vx, vy) * PIXELS_TO_METERS * 3.6

            # 2. Heuristic load estimation
            hist_areas = list(bbox_size_history[trk.id])
            median_area = float(np.median(hist_areas)) if hist_areas else 1.0
            area_ratio = bbox_size_history[trk.id][-1] / (median_area + 1e-9)
            load_frac = np.clip((area_ratio - 1.0) / 0.6, 0.0, 1.0)

            # 3. Get speed limit from datasheet based on load
            est_load_kg = load_frac * (float(_loads.max()) if len(_loads) > 0 else 2000.0)
            allowed_max_kmh = interp_unloaded_max_kmh(est_load_kg) if load_frac < 0.12 else interp_loaded_max_kmh(est_load_kg)

            # 4. Outlier rejection and smoothing
            prev_speed = track_prev_valid_speed.get(trk.id, kf_speed_kmh)
            speed = kf_speed_kmh
            if speed > allowed_max_kmh * 1.6 or speed > ABSOLUTE_MAX_KMH:
                speed = prev_speed # Reject spike

            track_speed_history[trk.id].append(speed)
            median_speed = float(np.median(track_speed_history[trk.id]))
            smoothed = 0.6 * median_speed + 0.4 * prev_speed
            smoothed = min(smoothed, allowed_max_kmh * 1.05) # Cap at slightly above allowed

            # --- Store final values for this frame ---
            objects_stats[trk.id]['speeds'].append(smoothed)
            objects_stats[trk.id]['distance'] += (smoothed / 3.6) * frame_dt
            objects_stats[trk.id]['frames'] += 1
            track_prev_valid_speed[trk.id] = smoothed
            track_smoothed[trk.id] = smoothed
            track_load_fraction[trk.id] = load_frac

        # --- Handle Unmatched Tracks and Detections ---
        for u in unmatched_trks:
            tracks[u].mark_missed()
            if not tracks[u].active:
                lost_tracks[tracks[u].id] = tracks[u]
        tracks = [t for t in tracks if t.active] # Filter out inactive

        for d_idx in unmatched_dets:
            det = detections[d_idx]
            if det['conf'] > NEW_TRACK_MIN_CONF:
                new_t = Track(det['bbox'], det['conf'], frame_idx, det['feature'], dt=frame_dt)
                tracks.append(new_t)
                bbox_size_history[new_t.id].append((new_t.bbox[2]-new_t.bbox[0]) * (new_t.bbox[3]-new_t.bbox[1]))

        # --- Visualization ---
        vis = frame.copy()
        if not tracks:
            draw_text_with_background(vis, "No Forklift Detected", (50, frame_h // 2))

        for t in tracks:
            load_frac = track_load_fraction.get(t.id, 0.0)
            is_loaded = load_frac >= 0.12
            cur_speed = track_smoothed.get(t.id, 0.0)

            est_load_kg = load_frac * (float(_loads.max()) if len(_loads) > 0 else 2000.0)
            allowed_speed = interp_loaded_max_kmh(est_load_kg) if is_loaded else interp_unloaded_max_kmh(est_load_kg)

            color = BBOX_COLOR_DEFAULT
            if cur_speed > allowed_speed:
                color = (0, 0, 255) # Red for overspeed
            elif is_loaded:
                color = (0, 140, 255) # Orange for loaded

            labels = [f"ID: {t.id}", f"Speed: {cur_speed:.1f} km/h"]
            draw_box_with_label(vis, t.bbox, labels, color=color)

            if SHOW_TRAJECTORIES and len(t.history) > 1:
                pts = np.array(list(t.history), dtype=np.int32).reshape((-1, 1, 2))
                cv2.polylines(vis, [pts], False, (0, 255, 255), 2)

        # Clean up old lost tracks
        lost_tracks = {lid: lt for lid, lt in lost_tracks.items() if frame_idx - lt.last_seen <= MISS_TOLERANCE_FRAMES}

        # Info text
        info_text = f"Frame:{frame_idx}/{total_frames} | Active Tracks:{len(tracks)}"
        draw_text_with_background(vis, info_text, (10, 30), scale=0.7, pad=8)
        out.write(vis)

        if frame_idx % 100 == 0:
            print(f"Processed {frame_idx}/{total_frames} frames...")

    cap.release()
    out.release()
    video_info = {'path': VIDEO_PATH, 'total_frames': frame_idx, 'fps': fps}
    export_tracking_data_to_csv(objects_stats, CSV_OUTPUT_PATH, video_info)
    print(f"âœ… Processing complete. Output video saved to: {OUTPUT_PATH}")


if __name__ == '__main__':
    main()

from google.colab import files

    # Assuming 'my_file.txt' is a file in the Colab environment
    files.download('/content/output_video_cleaned.mp4')